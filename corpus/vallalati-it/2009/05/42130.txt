Extrém memóriakapacitású Nehalem-blade a Ciscótól

Mikor január elején a New York Times nyomán kipattant, hogy a Cisco belép a szerverpiacra, a HWSW úgy spekulált, hogy a Cisco kezdetben talán egy más vállalat, például az Intel által elõállított blade szervereket fog alkalmazni, így gyorsítva fel a piacra lépés idejét, és csökkentve a belépéssel járó költségeket és ezzel a kockázatokat is. A jelek szerint azonban a vállalat ennél sokkal agresszívebb, és riválisainál is nagyobb kutatás-fejlesztési erõforrásokat dedikált annak érdekében, hogy egyedi megoldással különböztesse meg magát -- a vállalat láthatóan nagyon eltökélt, hogy bizonyítson a szerverpiacon is.
Extrém kapacitás
A Cisco mérnökei olyan egyedi tervezésû célchipeket (ASIC) hoztak létre, melyekkel megsokszorozható az Intel Nehalem-szervereinek maximális memóriakapacitása, és lényegében a fizikai méretek jelentették az egyetlen korlátot. A Nehalem-EP (Xeon 5500 sorozat) chipek egyenként legfeljebb 9 darab DDR3 (R)DIMM-et tudnak fogadni, így egy teljes kiépítettségû rendszerben megvalósítható maximális memóriakapacitás a jelenlegi elérhetõ 8 gigabájtos modulokkal 144 gigabájt lehet. Bár ez a legtöbb területre bõségesen elegendõ, a Cisco által megcélzott, adatközpont méretekben gondolkodó ügyfeleknek vannak olyan alkalmazásaik, mint például az üzleti intelligenciát támogató adatbányászat vagy online tranzakcionális rendszerek, melyek gyakorlatilag kielégíthetetlen memóriaéhséggel rendelkeznek, de tipikusan a virtualizációval konszolidált környezetek is rengeteg memóriát emésztenek fel egy-egy gazdagépen.
A Cisco Extended Memory Technology megoldásával egy Cisco B250 M1 blade 48 DIMM-et fogadhat, így 384 gigabájt érhetõ el vele. A vállalat egyedi tervezésû, teljesen transzparens ASIC-okat rak a Nehalem egy-egy csatornáira, melyek bufferként viselkednek és egyúttal továbbosztják azt további négy darab alcsatornára, alcsatornánként két foglalattal. Ezzel a korábbi maximális 3 DIMM-el szemben immár 8 DIMM-et fogadhat csatornánként a Nehalem, foglalatonként pedig 24-et, azaz 2,67-szeresére ugrik a maximális kapacitás -- immár egyetlen Xeon 5500-as processzort is harmadával több memóriával tudunk ellátni, mint amennyit egy teljes rendszer eddig képes volt lekezelni. 




A Cisco megoldása kísértetiesen emlékeztet az FB-DIMM által megvalósított koncepcióra, itt azonban egy dedikált buffer fedi el és kezeli az összes modult, miközben a processzor memóriavezérlõje errõl mit sem sejt. Az FB-DIMM esetében minden modulon saját buffer található, és a memóriavezérlõnek is FB-DIMM-ekhez kell beszélnie. Az FB-DIMM elõnye, hogy lényegében teljesen elfedi a mögötte lévõ memóriachipek technológiáját, így a memóriavezérlõ lényegében az aktuálisan legolcsóbb memóriatechnológiát tudja alkalmazni, továbbá csatornánként sokkal kevesebb huzalozást igényel, vagyis magasabb sávszélesség kiépítését teszi lehetõvé ugyanakkora költség és terület mellett. Hátránya azonban a nagy memóriakapacitás esetén a jóval magasabb rendszerfogyasztás, a modulok magas ára. A Cisco diszkrét egységes buffer megoldása ezzel szemben úgy növeli meg drasztikusan a memóriasûrûséget, hogy közben nem hoz magával jelentõs extra költségeket vagy fogyasztást.
Költséghatékony memóriabõvítés
A maximálisan elérhetõ kapacitás mellett egy további akadály is tornyosul az optimális memóriamennyiség kiépítése, mégpedig az ár, véli a Cisco. A memóriakapacitás növeléséhez egy idõ után nagyobb modulokat kell alkalmaznunk, ha elfogytak már a szabad foglalatok. Márpedig a nagyobb modulok aránytalanul drágábbak, a&nbsp;8 gigabájtos modulok például akár 8-10-szer drágábbak a 2 gigabájtosaknál, vagyis egységnyi kapacitásért több mint kétszeres árat kell fizetni. A memóriaárak folyományaként ha processzorfoglalatonként 36 gigabájt (9x4GB) fölé akar valaki menni, akkor drasztikusan el kezd emelkedni a memória gigabájtonkénti ára. A Cisco egyedi megoldása itt is segít, mégpedig azzal, hogy a több modulhely lehetõvé teszi a jobb ár-kapacitású DIMM-ek használatát a memória mennyiségének bõvítésében. 




Példának okáért ha 48 gigabájtot kellene adnunk egy-egy Nehalemnek, akkor ezt megtehetjük ugyan a hagyományos rendszerekben is, azonban csak a rendkívül drága 8 gigabájtos DDR3 ECC RDIMM-ekkel. A Cisco bufferelt megoldásával akár 2 gigabájtos modulokkal is megúszhatjuk -- harmad-negyedáron. A megtakarítás jóval meghaladhatja a másfél millió forintot is, mégpedig processzoronként.
A Cisco állítja, a buffer minimális teljesítménybeli csökkenésbe kerül a modulok magasabb késleltetésû hozzáférése miatt, nagyobb kapacitás kiépítése esetén pedig jelentõsen növekedhet is a teljesítmény az adatok magasabb lokalitása, valamint a memória általánosan magasabb találati aránya révén -- kevesebbszer kell a lassú háttértárak felé fordulni. A Cisco állítja, a buffer jelentette extra késleltetés jóval kisebb, mint a távoli memória másik processzoron keresztüli elérése. 






A Cisco B250 M1 blade szerverei, melyben a memóriabõvítõ bufferek megtalálhatóak, a közeljövõben érkeznek, egyelõre pontosan nem ismert idõpontban, és az árakat is sûrû köd fedi. A B250 M1a Cisco saját UCS 5100 keretébe illeszkedik horizontálisan,&nbsp; és teljes szélességben, így a 6U magas keret összsen négy darabot képes fogadni, még fél szélességûbõl nyolcat. A keret kommunikációjáért egy külsõ, 20/40 portos Cisco UCS 6100 Series Fabric Interconnect felel, mely egy veszteségmentes 10 Gigabit Ethernet switch, és támogatja az FCoE protokollt is.