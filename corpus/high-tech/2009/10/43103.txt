Nem viccelt az NVIDIA: az Intel skalpjára hajt

Na persze
Mikor az AMD ATI Radeon 5800 generációjának rajtjakor az NVIDIA figyelemelterelõ ellenrendezvényeket szervezett, méghozzá mindenféle termékbejelentés nélkül, kézenfekvõ volt azzal a feltételezéssel élni, hogy a cég nem rendelkezik megfelelõ válasszal. Igazán meglepõ volt azonban, hogy ezt Igor Stanek regionális PR-menedzser kategorikusan nem is tagadta, sõt felvetette annak lehetõségét is, hogy az AMD grafikus chipje talán felülmúlja majd az NVIDIA következõ generációját, de hangsúlyozta, bárhogyan is legyen, mindez nem igazán számít már.
Hogy miért? Mert az NVIDIA szerint a chipek jövõje többé nem azon fog múlni, hogy a lehetõ legnagyobb grafikus teljesítmény adják le, hanem azon, hogy mennyire tudnak egyre inkább általános célú, rugalmasan használható processzorokká fejlõdni. Olyan processzorokká melyeket a nagy számítási kapacitásra éhes mérnöki és tudományos (HPC) rendszerek, valamint a tömegtermékek, mint a PC-k és okostelefonok is egyaránt tudnak sokféle feladatra hasznosítani,  természetesen más és más implementációban, szem elõtt tartva a megcélzott eszközök fogyasztási és költségbeli kereteit.

Az NVIDIA nem most kezdett el beszélni errõl az irányról, sõt azt, hogy komolyan gondolja a grafikus chipek általános alkalmazhatóságát, vagyis a GPGPU koncepcióját, lényegében bebizonyította a CUDA programozási környezet két és fél évvel ezelõtti bemutatásával, melyet tucatnyi HPC- és multimédiás alkalmazás aknáz ma már ki. Az azonban, hogy a vállalat már nyíltan felvállalja, hogy nem a 3D (raszterizációs) grafikus teljesítmény az elsõdleges, és hogy erre jobban (túlságosan is) fókuszált az AMD, egy újabb szintre léptette elképzelését, pestiesen szólva: ez már meredek.
És tényleg
Mindez persze bárki számára tûnhet terelésnek, hiszen beszélni bármikor és bármennyit lehet, mely elfedheti a valóságot, például azt, hogy az NVIDIA egyszerûen nem versenyképes, és nagy gondok lehetnek a GT300 kódnéven ismert fejlesztésével. A Fermi, avagy helyesen GF100 architektúra létezése azonban minden kétséget kizárólag bebizonyítja azt, hogy az NVIDIA mennyire komolyan gondolja a GPGPU irányt, és hogy az elmúlt hónapokban új irányt vett kommunikációja mögött nem a tûzoltás áll, hanem egy évek óta tartó fejlesztés érett be.

A Fermi célja, hogy áttörést érjen el a programozhatóság és a megcélzott HPC- és multimédiás területekre jellemzõ kódok futtatása terén. Mindezt részben az általános célú, modern mikroprocesszorok néhány kulcsfontosságú kód- és memóriavezérlési technikájának (például indirekt elágazásbecslés, kivételkezelés) átvételével éri el, másrészt pedig a cache-hierarchia és végrehajtó magok szervezésének egyszerûsítésével, valamint az egyes magok képességeinek drasztikus megerõsítésével.
A Fermi a szélesebb körû alkalmazhatóság érdekében már támogatja az ECC memóriát is. Ha néhány pixel egy frissítésnél rosszul jelenik meg, semmi probléma, észre sem venni, egy pénzügyi vagy tudományos számításnál azonban gigantikus eltéréseket okozhat egy minimális hiba is. Az NVIDIA nem kevesebbet célzott meg, minthogy a jelenlegi GT200-hoz képest nyolcszorosára növelje a 64 bites lebegõpontos teljesítményt - ez 600 gigaflops nyers kapacitást jelentene, ami nagyjából tizenkétszerese a leggyorsabb Nehalem chipének, vagyis számítási erõforrásokban nem szûkölködik a Fermi. Igaz, ezen erõforrások kihasználtsága továbbra is a feladat párhuzamosíthatóságától és a kód minõségétõl függ leginkább.
Egy extrém párhuzamosságú processzor
Ha szakítunk az NVIDIA terminológiájával, akkor a Fermire pillantva egy 16 magos processzor rajzolódik ki elénk, ahol a magok saját dedikált L1 utasítás- és adattárakkal és belsõ vezérléssel rendelkeznek, és egy közös L2 cache-re csatlakoznak. A magok ugyanakkor nem függetlenek teljesen, egy globális ütemezõ rejti el õket a külvilág elõtt, így a szoftverek szempontjából továbbra sem lehet többmagos chiprõl beszélni, legalábbis olyan értelemben nem, ahogyan azt a többmagos processzoroknál megszoktuk.

Az L1 cache immár koherenciát biztosít a magon belüli szálak és végrehajtóegységek közt, és tartalmát idõrõl idõre kiírja a mag az L2 térbe, hogy más magok és a rendszer számára is láthatóak legyenek az eredmények - ez az úgynevezett félkoherencia, mivel nincs teljes védelem az ellen, hogy egyetlen címre más és más eredményeket írjon vissza kettõ vagy több mag, amit így a programozónak vagy a fejlesztõeszközöknek kell felügyelnie, hogy ne történhessen meg.
Mindez  gyökeres eltérést jelez az elõdhöz képest, ahol 30 mag hármasával osztozott az L1 tárakon, melyek ráadásul semmilyen szintû koherenciát nem biztosítottak, és eredetileg textúrázásra termettek. A különbségek azonban csak most kezdõdnek. A globális ütemezõ, mely kiosztja a magoknak a feladatokat, immár 16 különbözõ programszelet/szál (az NVIDIA terminológiájában kernel) állapotát tudja nyilvántartani, és kezelni a párhuzamos végrehajtásukat, szemben a korábbi eggyel, ami megnöveli a magok kihasználtságát, és hatékonyabbá teszi a chipet kisebb kernelek fogadására is.
Mindezt elõsegítendõ az ütemezõ a korábbinál tízszer gyorsabban tud kontextust váltani, igaz, ez számítástechnikai dimenzióban még mindig hosszadalmas, hiszen 25 ezer nanoszekundumot vesz igénybe, ami egy 1 gigahertzes áramkör esetében 25 ezer ciklus elpazarlását jelenti - összevetésképpen egy távoli memória elérése tipikusan legfeljebb néhány száz ciklus.
Masszív erõforrások
Ha belépünk az egyes magokba, hatalmas különbségeket látunk az elõdökhöz képest. Az egyes magokban, vagyis streaming multiprocesszorokban, ahogyan az NVIDIA nevezi õket, a számítási erõforrások megnégyszerezõdtek, miután két futószalagon egyenként 16 végrehajtóegység (CUDA Core) található, mindegyikben egy 32 bites egészpontos (ALU) és egy 32 bites lebegõpontos (FPU) egységgel, melyekbe egyszerre az egyikhez lehet utasítást betölteni, mivel közös porton találhatóak.
Egy mag tehát összesen 64 végrehajtóegységgel rendelkezik. A 64 bites lebegõpontos számításokkor mindkét futószalag párhuzamosan dolgozik, és egy támogató logika segítségével összeolvasztják az eredményeket. Az NVIDIA ezzel megoldotta, hogy nem jelentkezik extra lassulás  64 bites mûveletek végrehajtásakor, hanem a kétszeres szélességnek megfelelõen pontosan feleannyi a sebesség mint a 32 bites feldolgozás esetén, megszüntetve ezzel a processzorokkal szembeni relatív hátrányát. A chip már teljesen szabványos, IEEE 754-2008 mûveleteket végez a pontosság érdekében. A magok a kernel darabkáit blokkokban (thread blocks) fogadják, a blokkokat pedig tovább szeleteli és csoportosítja a mag utasításláncokká (warp), és ezeket a dekódolt láncokat ütemezi be a futószalagok számára.
Ha egy mag befejezi egy adott kernel végrehajtását, az eredményeket visszaírja az L1 adattárból az L2 cache-be, mely 6 darab 128 kilobájtos bankból épül fel. Az L2 cache a chip globális memóriamûveletek vezérlésére hivatott, és szinkronban tartja a magokat is, valamint az alkalmazás globális állapotát, ahogyan a végrehajtás szinkronizációját is támogatja - mindez persze rendkívül komplex feladat, ami a politikák és algoritmusok alapos tervezését és megvalósítását követeli meg. A chip immár 40 bites, lapos fizikai és virtuális memória címtartományt alkalmaz a globális címzés érdekében, és TLB-t a kettõ közötti átjáráshoz, ami szintén alapvetõ változás a rugalmasság felé, és egy újabb elem, mely hasonlatossá teszi az általános célú processzorokhoz.
A külsõ memóriát a Fermi immár nem GDDR3- hanem GDDR5-vezérlõkön éri el, ami sokkal hatékonyabbá teszi a magasabb sávszélességek elérését. A hat darab, egyenként kétcsatornás vezérlõ összesen 384 bit szélességgel fér hozzá a memóriához, így elméletileg elérhetõ a 230,4 GB/s nyers sávszélesség 1200 megahertzes memória órajel (4,8 gigatranszfer/s) mellett. A memória sebessége vélhetõen attól is függ majd, hogy milyen piacra szánja majd az adott terméket az NVIDIA, legnagyobb sebességgel  vélhetõen a játékra szánt videokártyák rendelkeznek majd.
Programozás
A programozhatósághoz azonban szoftveres eszközökre is szükség van, és az NVIDIA itt is aktívan dolgozik azon, hogy egyre több szoftverfejlesztõhöz érjen el. Mire piacra kerülnek az elsõ Fermi termékek (melyekrõl egyelõre semmit nem beszélt az NVIDIA), addigra a CUDA környezetben már C   nyelven is lehet az alkalmazásokat írni a módosított C, Java, Python és Fortran mellett. Ezzel párhuzamosan a Visaul Studióval is integrált fejlesztõi környezetet is kifejlesztett a cég Nexus néven, mely képes heterogén, vagyis az x86 és grafikus processzorokon egyszerre futó alkalmazásokat létrehozni. Az NVIDIA természetesen a CUDA-t támogatja elsõsorban, de a Fermi DirectX 11-es API fogadására felkészített architektúra, ahogyan az OpenCL-t is támogatja.
Hogy a Fermi termék formájában mikor jelenik meg, egyelõre nem tudni, ezzel kapcsolatban az NVIDIA semmit nem közölt, Stanek ígérete szerint még év vége elõtt megvásárolhatóak lesznek az elsõ változatok. Ez azt sugallja, hogy szélesebb körben csak jövõ év elsõ felében indul meg a Fermire épülõ termékek gyártása és terjesztése.
Zárszó, kitekintés
A fejlesztések eredményeként a Fermi elõdeinél sokkal hatékonyabb, és többszörös teljesítményû lehet az olyan masszívan párhuzamos természetû számítási feladatokban, mint amilyen például a valósidejû adatvizualizáció és képmanipuláció, videoszerkesztés, ray-tracing, áramlástani szimulációk, statisztikai elemzések, vagyis HPC és PC-felhasználásra egyaránt alkalmasabbá válhat. Az NVIDIA közzététele itt olvasható.
Mivel termékrõl nem esett szó, és a szilíciumról is lényegében csak annyit tudni, hogy a TSMC 40 nanométeres eljárásán készül, és 3 milliárd tranzisztorból áll, ezért az órajelekrõl és a leadott  teljesítményrõl sem lehet pontos képünk, fõleg nem a grafikus teljesítményérõl, mivel az architektúra ezen aspektusáról nem beszélt a cég. Minden jel arra utal azonban, hogy az NVIDIA megpróbált megalkotni egy csúcsteljesítményû processzort, mely gyártásba kerülésekor a világ egyik, ha nem a legintegráltabb és legnagyobb chipje lesz, mely eddig tömegtermelésbe került, és melynek technológiája késõbb majd a piac alsóbb szegmensei számára is lecsorog.
A Fermi lélektani jelentõsége hatalmas, ezt követõen ugyanis az NVIDIA törekvését, hogy rövid idõn belül átvegye az uralmat a PC-k lelkében, elhomályosítva az x86-os processzorok jelentõségét, nem lehet nem komolyan venni. Természetesen szó nincs arról, hogy a belátható idõn belül ne volna szükség x86-os chipekre, hiszen mindezt megköveteli a PC-világ kompatibilitása, ugyanakkor a hangsúly a GPGPU, mint koprocesszor felé tolódhat el, ahogyan egyre több feladatot képes átvenni a hagyományos processzoroktól, és hatékonyabban elvégezni azt.
Mindez azt jelentené a piac több mint 80 százalékát uraló Intel számára, hogy a piac relatíve egyre kevesebbet költene x86-os chipekre, és egyre többet az újfajta koprocesszorokra, melyet az NVIDIA szállítana. Az NVIDIA szerint ennek a trendnek egyik elõfutára az Atom-Ion páros, melynél egy 40 dolláros Intel processzor is elegendõ ahhoz, hogy Windows 7 Aero folyékony megjelenítésére, 1080p videók vagy World of Warcraftot és Sims lejátszására alkalmas rendszert építsünk, nem szükséges 100-200 dolláros processzorokat megfizetnünk hozzá. Gyakorlatilag egy "hétköznapi" felhasználás elõtt az utolsó akadály a nagy felbontású flash videók és animációk jelentik, hamarosan azonban ez is megoldódik, ahogyan egy következõ Flash Player frissítés már képes lesz a GPU-kon gyorsítani azt is, így a Youtube HD-t is élvezhetjük hamarosan netbookokon is.
Úgy tûnik, ez csak a kezdet, az NVIDIA Fermi hatalmas elõrelépést képvisel a GPGPU irányban, hardveres és szoftveres oldalról egyaránt, és idõvel, valószínûleg nagyjából egyéves távon az architektúra leszivárog a notebookok területére is. Az jelenlegi ismeretek szerint az Intel ez kétféle stratégiai kezdeményezéssel válaszol: az ultrahordozható notebookok és olcsó gépek terén igyekszik minél szorosabban a processzorhoz integrálni a grafikus magot és a chipsetet, másrészt pedig gõzerõvel dolgozik a Larrabee-n, mely az Intel diszkrét, masszívan párhuzamos architektúrájú vizualizációs és HPC-chipje, avagy a saját GPGPU-ja.
A jövõ év elején megjelenõ Westmere generáció már a processzorral közös tokon belülre emeli a grafikus magot, és ez az új rendszerarchitektúra késõbb a netbookok terén is megjelenik, így nagyjából másfél-két éven belül az egész ultramobil palettát lefedi majd. Mindez azt jelenti, hogy az NVIDIA csak extra költségként tud megjelenni ezekben a PC-kben, ugyanis nincs lehetõség arra, hogy az Intel helyett NVIDIA integrált chipsetet építsen a gépbe a gyártó - mindenképpen meg kell fizetni az Intel grafikus chipet, így drasztikusan csökken az NVIDIA piaca. Ésszerû lépés volna saját x86-kompatibilis platformmal megjelennie a cégnek, errõl azonban mélyen hallgat.
Az Intel másik eszköze a GPGPU nagyteljesítményt igénylõ felhasználási területeken történõ védekezést, avagy ellentámadást célozza. Ez a Larrabee projekt, mely lényegében az Intel elsõ próbálkozása, hogy egy diszkrét, kifejezetten csúcsteljesítményû grafikus chipet alkosson. A Larrabee-t az Intel néhány hete már demózta az Intel Developer Forumon, ahol a Quake Wars egy interaktív ray-tracing változatát futtatta, demonstrálva képességeit.
Az eddig nyilvánosságra került információk alapján a Larrabee erõteljesen vektorizált (512 bit széles végrehajtás, Larrabee New Instructions), egyszerûsített x86 magokból épül fel, melyeket körbusz köt össze, és a grafikus alkalmazhatóság érdekében extra textúrázó és raszterizáló egységeket is kap. A Larrabee architektúrája idõvel a processzorral integrált megoldásokban is megjelenik majd, közölte az Intel. Hogy mire lesz képes, és hogyan állja meg a helyét például a Fermivel szemben, egyelõre még csak tippelni sem lehet, fõként mivel egyik végleges specifikációit sem ismerni, ráadásul nincsenek olyan kiforrott kódok, melyeket sztenderdként elfogadva megfelelõ összevetési alapot adnának - 2010 izgalmas évnek ígérkezik a számítástechnika történetében.	     
                  
                  
                  
                   