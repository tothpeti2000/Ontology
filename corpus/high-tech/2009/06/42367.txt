Moore törvénye él, és élni fog

A régi eszköz kicsorbulhat
Mikor Gordon Moore több mint negyven évvel elõször írta le megfigyelését az integrált áramkörök komplexitásának tartós fokozódásáról, a hajtóerõt a struktúrák méreteinek miniatürizálása jelentette. Ez igaz maradt az azt követõ évtizedekben is, a gyártók egyre kisebb és kisebb tranzisztorokat és vékonyabb huzalozást fejlesztettek ki, így egyre összetettebb, nagyobb teljesítményû chipeket dobhattak piacra.
A miniatürizáció szinte tökéletesen mûködött egészen az ezredfordulóig, pontosabban nagyjából a 180-130 nanométeres csíkszélességig. A gyártók minden egyes félvezetõgeneráció-váltásnál egyszerre söpörték be az elérhetõ összes elõnyt, vagyis duplázták a gazdaságosan egy lapkára integrálható tranzisztorok számát, miközben növekedett a tranzisztorok sebessége és drasztikusan csökkent a fogyasztásuk is.
Ezt követõen, vagyis a 90 nanométeres és az alatti geometrikákon a gyártók jelentõs problémákba ütköztek, ugyanis a tranzisztorok sûrûségét meghatározó csíkszélességgel nem skálázódhatott büntetlenül tovább például a tranzisztorok kapuoxidjának vastagsága és hossza, mivel ez a szivárgási áram drámai növekedését okozta. A tranzisztorok sebesség-energia karakterisztikája megváltozott, a gyorsaság és fogyasztás között immár választani, egyensúlyozni kellett. Ennek eredményeként korábban nem látott jelenségként elszabadult a fogyasztás, aminek határt kellett szabni, és az azóta piacra került PC- és szerverprocesszorok teljesítményét ez limitálja elsõsorban.
Ezeket a gondokat a gyártók különféle anyagtechnológiai áttörésekkel kezelték, hogy továbbra is megpróbálják hozni a korábban megszokott elõnyöket, azaz növekvõ teljesítmény alacsonyabb fogyasztás mellett. Ilyen technikák a szilícium molekulaszerkezetének kifeszítése, vagy az fémkapuk és fém kapuszigetelõk bevezetése, melyeket elsõként az Intel alkalmazott, de az ígéretek szerint az IBM és partnerei, valamint a TSMC is követik késõbbi félvezetõgyártási generációkban. Mindezek az áttörések, melyek a szélesebb publikum figyelmét elkerülve csendben történtek, lehetõvé tették, hogy a vállalatok kidolgozzák 22 nanométeres csíkszélességet megvalósító eljárásaikat, melyek mûködõképességét SRAM-chipekkel bizonyították már, miközben a háttérben már javában folyik a 16-15 nanométeres eljárások kifejlesztése, és a késõbbi technológiák kutatása.
[ ] Közel a félvezetõipar történelmének vége 
A 22 nanométeres technológiákkal a következõ öt év során garantáltak a Moore törvénye jelentette elõnyök: fokozódó teljesítmény, alacsonyabb fajlagos termelési költség és fogyasztás. Mi lesz azonban ezután? Hogyan lehet lemenni 20 nanométeres csíkszélesség alá? Ezt egyelõre legfeljebb a világ néhány félvezetõipari kutatás-fejlesztési laborjában sejtik. Az egyik sarkalatos kérdés, hogy addigra készen állnak-e majd az úgynevezett extrém ultraibolya tartományban mozgó fotolitográfiai (EUVL) berendezések, melyekkel rendkívül magas optikai felbontás érhetõ el a 13,5 nanométeres hullámhossznak köszönhetõen -- a jelenlegi berendezések 193 nanométeres ultraibolya fénnyel dolgoznak. Az EUVL azonban a vártnál több és nagyobb problémával küzd -- mint például a levilágítási teljesítmény és a defekciós ráta, melyeket most nem tárgyalunk --, így használata nem várható a 16 nanométeres csíkszélesség elõtt, melynek bevezetése legkorábban 2013-14 magasságára várható.
Chipek egymáson
Moore törvényének csorbulása azonban gyakorlatilag kizárt, köszönhetõen az olyan óriásoknak, mint az Intel, az IBM, a Samsung Electronics, a Toshiba és a TSMC. Ha technológiai okokból vagy egyszerûen a fizika törvényei miatt a struktúrák méreteit nem is tudják majd egy idõ után a korábban megszokott ütemben zsugorítani, a gyártók továbbra is fokozni tudják majd az egy területre zsúfolható tranzisztorok számát. A probléma megoldása a hétköznapokban kézenfekvõ: hogyan rakjunk be még több dobozt egy 30 négyzetméteres szobába, ha már nincs több hely padlón? Pakoljuk õket egymásra!
A mai chipek kialakítása topológiai szempontból szigorúan kétdimenziós. A gyártók azonban már ma rendelkeznek olyan 3D-tokozási technikákkal, melyek a jövõben egyre inkább segíteni fogják, hogy az iparág továbbra is fenntartsa Moore törvényét, vagyis nagyjából kétévente megduplázódjon a gazdaságosan integrálható tranzisztorok száma. Ennek triviális módja, mikor egymásra rétegeznek diszkrét chipeket, és összekapcsolják, majd együtt betokozzák azokat. Ilyen módszert már tömegtermelésben is használ a memóriaipar, annak érdekében, hogy a lehetõ legalacsonyabb költség mellett a legnagyobb kapacitású termékeket tudják kínálni. A Samsung Electronics például négy darab 4 gigabites DDR3-chipet rétegez és tokoz egybe, így válik lehetõvé a napokban bejelentett 32 gigabájtos DDR3 DIMM is, de hasonló stackelési technikával más memóriagyártók is rendelkeznek. Ebben az esetben a fõ vezérelv a takarékosság: nem kell chipenként tokozni, amivel a rendkívül nyomott árú memóriák esetében jelentõs költség spórolható meg.
Mindez önmagában még nem volna elegendõ, hiszen ettõl még egy az egyes chipek elõállítása nem lesz olcsóbb, és a teljesítmény nem növekszik -- a Samsung is az extrém sûrûség elérése érdekében alkalmazta a 3D stackelést. A mérnökök azonban ezekre a 3D-s gyártási technikákra alapozva a jövõben kifejezetten 3D-felépítésû architektúrákat alkothatnak, vagyis egy integrált áramkört kettõ vagy több egymáson fekvõ szilíciumchipen implementálnak. Ennek számos gyakorlati elõnye lehet, így például az egyes blokkok elektronikailag közelebb kerülhetnek egymáshoz, vagyis rövidebb összeköttetéssel kapcsolódhatnak, ami alacsonyabb késleltetést és fogyasztást jelent. Az Intel már 2006 decemberében prezentálta azt a kísérleti Pentium 4 processzort, melyet három dimenzióban alakított ki. A lazább idõzítéseknek köszönhetõen a 3D Prescott futószalagjának hosszát negyedével lehetett rövidíteni, így a fogyasztás összesen mintegy 20 százalékkal csökkent, miközben a teljesítmény 15 százalékkal megugrott -- ez egy ideális félvezetétechnológiai generációváltáshoz hasonló eredmény.


Bár a költségbeli vonzatról az Intel nem nyilatkozott, kétségtelen, hogy ha egy adott integrált áramkört több chipen hozunk létre, akkor az egyes chipek kisebbek lesznek, mint a hagyományos  megközelítésben. Szigorúan a szilíciumköltségeket nézve ebbõl egyenesen következik, hogy alacsonyabb elõállítási költség érhetõ el a magasabb kihozatalnak köszönhetõen: ha három egyenlõ chipbõl épül fel, akkor az egyiken keletkezett gyártási hiba miatt nem kell a másik kettõ is kidobni, ráadásul a köralakú szilíciumszeletek szélein keletkezett veszteség is kevesebb a kisebb chipeknek köszönhetõen.  Ezt a lehetõséget jól érzékeltetik az Intel 2006 végén debütált multi-chip négymagos processzorai, melyek kihozatala 20 százalékkal magasabb lett a vállalat becslése szerint egy monolitikus felépítésûvel szemben, vagyis a megközelítés mintegy 16 százalékkal alacsonyabb elõállítási költséget jelentett. Ez a 16 százalék nagyjából egy fél generációnyi félvezetõtechnológiai váltással egyenértékû, amit az architektúrák 3D-re célzott optimalizálásával valószínûleg tovább lehetne fokozni, és elérhetõ volna a 25-30 százalék is.
Háromdimenziós cellák
Itt azonban közel sem áll meg a 3D-s chiptechnikák tudománya. A Toshiba múlt hét végén jelentette be a Kiotóban megrendezett 2009 Symposia on VLSI Circuits konferencián legújabb 3D-stackelési technológiáját, mely nem chipeket, hanem cellastruktúrákat rétegez egymásra. Az úgynevezett Pipe-shaped Bit Cost Scalable (P-BiCS) technológiával a japán vállalat 60 nanométeres csíkszélességû eljárással 16 cellszintet épített egymásra, cellánként 2 bittel, így az adatsûrûsége bitenként mindössze 0,00082 négyzetmikrométer, ami tizede a hasonló geometriai felbontású NAND-chipekének, azaz adott területen tízszeres kapacitást képes létrehozni.
A koncepció szokás szerint egyszerû, miközben a megvalósítás évek hosszú munkájának eredménye, a most publikált eredmény már második generációs fejlesztés, a BiCS megoldással már 2007-ben jelentkezett  a cég. A Toshiba második generációs BiCS cellarétegzési technológiája felváltva alakít ki kapuelektróda és szigetelõ filmeket egymáson, miközben lyukakat képez ezeken a rétegeken át, melyeket feltöltve "pillérek" jönnek létre, így alakítva ki egy vezérelhetõ 3D-s cellatömböt, melynek magassága a mikrométeres tartományban mozog. Hasonló fejlesztésekkel a Samsung is rendelkezik, jelenleg azonban úgy tûnik, a Toshiba vette át a vezetõ szerepet e téren.
Ezek a 3D-technikák ugyan nincsenek egyelõre tömegtermelésben, alkalmazásuk korántsem science fiction csupán. A Toshiba P-BiCS fejlesztési csapata a következõ két-három éven belül akarja kidolgozni a technika tömegtermelésben alkalmazásának módját. Ehhez a struktúra kialakításának egyszerûsítésére van szükség, jelenleg a prototípus 16 szintjét ugyanis két menetben, kétszer 8 szint kialakításával érték el, ahogyan a vezérlõ "alagút" is jelenleg egyszerre nyolc réteget képes összekötni. Nem véletlen, hogy a Toshiba és a Samsung élen jár a 3D-s technikákban, hiszen a memóriaiparban a bitköltség az élet és halál ura, üzletük azon alapul, tudják-e tartani a NAND bitköltségének eddig megszokott csökkenési ütemét.
Az IBM már készen áll arra, hogy 3D-csomagolási technikákat alkalmazzon, állította a Nikkei Electronicsnak adott interjújában Bernard Meyerson, az IBM mûszaki vezérigazgatója, aki szerint a közeljövõben megkezdik az átállást, majd további 4-5 év múlva az iparág is hasonlóan tesz majd, ami várhatóan a processzor és a memória közelebb hozásával kezdõdik majd, ami a Moore törvény szempontjából bár kevésbé releváns, valójában hatalmas ugrást jelent majd teljesítmény és energiahatékonyság terén. A 3D-s technikák fejlesztéseire tett  erõfeszítések nem kiváltják, hanem kiegészítik majd a miniatürizálásra irányuló erõfeszítéseket, kompenzálva az esetleges kényszerû kompromisszumokat -- a fent említett megoldások csak példák a lehetõségekre, melyeket a 3D-chipek rejtenek.
A fizikai méretek további faragása jelenlegi szemmel hatalmas nehézségek elé néz a következõ évtizedben, mindez azonban közel sem jelenti a félvezetõipar fejlõdésének végét, sem a lassulását. Mint látható, a 3D-s technikák számos eszközt adnak majd a mérnökök kezébe arra az esetre is, ha a miniatürizáció üteme lelassulna, hogy továbbra is fenntartsák Moore törvényének érvényességét, mely egyúttal az egész iparág teljesítményének mércéje is -- 2015-ig, vagyis a törvény 50. évfordulójáig egészen biztosan. Az egyszerre izgalmas és félelmetes kérdés az, mi fog történni 2020 után.	     
                  
                  
                  
                   