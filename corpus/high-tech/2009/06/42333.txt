2009 fordulópont a számítástechnika történetében?

Az NVIDIA állítja, 2009-et hosszú ideig emlegetni fogjuk még, mint a számítástechnika történetének egy fordulópontját. A vállalat szerint végre valóra válik a régóta emlegetett ígéret, és megindul a videochipek 3D-grafikán túlmutató széleskörû alkalmazása, miután felépült a használatban lévõ GPU-k, szoftverek és tudás egy olyan kritikus tömege, mely lehetõvé teszi mindezt, egyúttal a piaci tendenciák is e felé mutatnak.
Összeáll a kirakó
"Úgy gondolom, helytálló azt mondani, 2009 egy olyan inflexiós ponthoz vezet, melyre éveken át emlékezni fogunk mindannyian" -- fogalmazott az NVIDIA elemzõi napján Huang. A vezetõ úgy gondolja, a PC-ipar és a PC-k mint termékek elvesztették korábbi vonzerejüket, és alapvetõen meg kell újulnia a számítástechnikai architektúrának ahhoz, hogy újra fel lehessen kelteni a fogyasztók érdeklõdését. "Egyszerûen nem szexi többé. [...] Annak érdekében, hogy újra szexié lehessen tenni, forradalmasítanunk kell az architektúrát. [...] Az eredeti processzor architektúra nem megfelelõ többé [...] A jó hír az, hogy a számítástechnikai ipar, beleértve a Microsoftot és az Apple-t is, eltökéltek hogy megtegyék ezt."
Huang ezzel a MacOS X v10.6 Snow Leopard és Windows 7 operációs rendszerekre utal, melyek közös jellemzõje, hogy gyárilag támogatni fogják a GPU-k általános célú programozhatóságát és számítási kapacitásuk bevonását az olyan korábban kizárólag a processzorok által kezelt területekre, mint az audio- és videoszerkesztés és -kódolás, valamint átfogóbb videolejátszási és 3D-grafikai képességek is lehetõvé válnak.
Az Apple az Open Computing Language, az OpenCL API-t dolgozta ki együttmûködésben az AMD-vel, az Intellel és az NVIDIA-val, mellyel úgynevezett heterogén futású kódok is alkothatóak, vagyis a mikroprocesszorok és grafikus processzorok erõforrásait egyaránt kiaknázhatják az alkalmazások. A Microsoft a Windows 7-tel vezeti be a DirectX compute shadereket, melyek szintén azt jelentik a programozók számára, hogy rugalmasan, egyszerûen adhatanak számítási feladatokat a grafikus processzornak is, anélkül, hogy azokat grafikus megközelítésben kellene tálalniuk. Az új PC-operációs rendszerek egyaránt idén õsszel, szeptemberben és októberben érkeznek meg.
Huang természetesen elismeri, hogy idõbe telik majd, mire az új megközelítés, az új programozási modell elterjed a piacon is, hiszen az elmúlt évtizedeket a programozók többsége "keskeny", szekvenciális utasításfonalakat eredményezõ kódok fejlesztésével töltötte, miközben a grafikus chipek hatékony kihasználásához nem csak fonál-, de utasítás- és adatszinten is masszívan párhuzamos, vagyis többszálúsított, vektorizált kód kell. Az áttéréshez szükséges erõfeszítéseket ösztönzi, hogy az AMD és az NVIDIA együtt több mint 200 millió olyan, egységes shader architektúrát megvalósító DirectX 10-es grafikus processzort szállított le, mely rugalmasan programozható lesz a Windows 7 és a DirectX 11-gyel frissített Vista rendszereken, és negyedévente további tízmilliókat adnak el, melyek egyre növekvõ számítási teljesítménnyel rendelkeznek, és egyre hatékonyabbak a nem grafikus feladatok futtatásában.
A PC-piac a tét
A GPU-k azonban nem csak a csúcsteljesítményû alkalmazási területeken érdekesek, sõt leginkább nem ott érdekesek, hiszen akkor megmaradnának az ipar és az akadémiai szektorok játékszerének. Az architekturális forradalom, melyrõl az NVIDIA beszél, akkor válik érdekessé, mikor a hétköznapi PC-ken belüli erõviszonyok változnak meg, és felhasználásuk átalakul ennek hatására. Az NVIDIA- propaganda eddig fõként arról harsogott, mennyire gyorsak a GeForce-ok, hála a CUDA-nak, mennyire verik meg a leggyorsabb x86 processzorokat.
Valójában a csúcsteljesítmény csak nagyon kevesek számára érdekes, kevesen hajlandóak megfizetni, és tudják kihasználni a legújabb hardverekben rejlõ potenciált. Ennél sokkal érdekesebb a hatékonyság, ami egyszerre takar költség- és energiahatékonyságot. A milliárd dolláros kérdés az, valóban jobb végfelhasználói élményt kapunk-e pénzünkért akkor, ha relatíve többet költünk GPU-ra, és inkább kevesebbet a processzorra -- és vajon a piac ennek megfelelõen szavaz majd pénzével egyre inkább a grafikus processzorokra?
Az NVIDIA mindenesetre hatalmas igennel felel erre a kérdésre, és állítja, jobban járunk árban, multimédiás teljesítményben és akkuidõben is, ha egy Atom-ION párost vásárolunk, nem pedig valamilyen Celeron, Pentium vagy Core 2 processzort és Intel integrált grafikát. Számára mindez azt jelenti, hogy a PC-re elköltött forintokból nagyobb arányban részesedik mint korábban, az Intel pedig kevesebbet kap. Ugyanezért reméli ARM-alapú Tegra okostelefon és "smartbook" platformjának széleskörû sikerét az NVIDIA, mellyel egyszerre ér el alacsonyabb fogyasztást és magasabb teljesítményt az Intel Atom és a Qualcomm Snapdragon platformokhoz képest, állítja. A gondolatmenet természetesen erõteljesebb konfigurációknál is igaz marad az NVIDIA szerint, vagyis inkább GPU-ra költsünk, mert több teljesítményt kapunk cserébe. Ez az állítás jelenleg rendkívül korlátozottan igaz, hiszen a GPU-végrehajtást jelenleg a szoftverek viszonylag szûk köre, fõleg zene- és videoszerkesztõk, valamint -lejátszók, illetve tudományos szimulációk támogatják csak.


Mindez azonban megváltozhat a A Windows 7 és a Mac OS X v10.6, valamint a DirectX 11-es grafikus chipek megjelenésével, amennyiben valóban hatékonyabbak lesznek az x86-os mikroprocesszoroknál, és ezt a tényt a szoftveripar is magáévá teszi. Kérdés persze, mennyi idõ alatt, a szoftverfejlesztõk többsége nem arról ismert, hogy alkalmaznák élenjáró hardvermegoldásokat: hiába lehet többmagos PC-processzort vásárolni immár négy éve, és hiába futtat 8 utasításszálat a Core i7, a PC-szoftverek nagy része pocsék párhuzamosítással bír, ha egyáltalán felkészítették rá.
Akárhogy is, az NVIDIA igen határozott jövõképének létjogosultságát igazolja az Intel Larrabee projektje, melynek célja kétségtelenül annak megakadályozása, hogy más vállalatok szilíciumára vándoroljanak el a kódok, és így a pénzek -- az NVIDIA 22 milliárd dolláros növekedési lehetõséget lát a GeForce-ok számára a PC-piacon, vagyis ennyit veszthetnek el mások. Amiben egyetértés látszik kibontakozni, hogy a két világ egyre közelebb kerül egymáshoz, a processzor és a grafikus chipek egyre több feladaton osztoznak meg majd a jövõben -- míg lehet egyáltalán különbséget tenni köztük.	     
                  
                  
                  
                   