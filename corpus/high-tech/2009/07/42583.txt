Extrém skálázható nyílt forrású adatbázis a Yale Egyetemrõl

A probléma
A nyílt forrású HadoopDB projekt vezetõjeként Daniel Abadi, a Yale számítógéptudományi karának adjunktusa úgy véli, a jelenleg használatban lévõ párhuzamos adatbáziskezelõk többsége hamarosan skálázódási problémákba fog ütközni, állítsanak bármit is azok szállítói. Véleménye szerint ezt több trend együttes mozgása idézi majd elõ: a szervezetek által kitermelt strukturált adatmennyiség rohamos mértékben növekszik, a jelek szerint gyorsabban, mint ahogyan a számítógépek kapacitása tud. A  strukturált adatok hasznosítása egyre összetettebb analitikát követel meg, az üzleti intelligencia iránti igény felfutóban van, ami a számítási teljesítmény iránti igényt is megnöveli.
Egy másik trend, hogy a vásárlók egyre inkább az olcsó x86-os szerverek fürtözése felé mozognak el nagyméretû, teljesítményigényes feladataik kiszolgálásakor, mivel a tömegpiac méretgazdaságosságát meglovagolva ez jóval költséghatékonyabb a nagyobb méretû SMP-számítógépek használatánál. Mindez azt eredményezi, hogy egy-egy gép, vagyis csomópont, viszonylag alacsony számítási potenciállal rendelkezik, hiszen költséghatékonyan tipikusan a kétfoglalatos szerverek szerezhetõek be.
Ezek eredõjeként a jövõben exponenciális ütemben fog az egy-egy klaszterben megtalálható csomópontok száma növekedni, véli Abadi. Úgy látja, míg a párhuzamos adatbáziskezelõ rendszerek néhány tucat, esetleg néhány száz csomópontig kiválóan skálázódnak, több ezer, vagy több tízezer csomópont esetén  már nem mûködõképesek. Ennek számos oka van, többek közt a nem eléggé fejlett hibatûrõ képesség, ami nagy installációk esetén különösen kritikus, hiszen itt a hibák gyakorisága gyakorlatilag rutinszerû, napi esemény, aminek nem szabadna megzavarnia az adatbázis mûködését -- egy átfogó lekérdezés elvileg akár ezernyi gépet vehet igénybe, így magas valószínûséggel következik be hiba, ami a lekérdezés által addig összegyûjtött adatok elvesztését is eredményezheti. A komplex, hosszan futó lekérdezések lefutása akár teljesen ellehetetlenülhet.
A másik, hogy ugyanígy gyakoribbá válnak a teljesítményproblémák, ugyanis egyre valószínûbb, hogy lassú lekérdezések jelennek meg a rendszerben, mivel egy-egy csomópont túlterhelõdött, vagy eltérõ hardverkonfiguráció miatt természetszerûleg más terhelhetõséggel rendelkezik. A mai adatbázisok többsége nem rendelkezik dinamikus feladatütemezéssel, mely a csomópontok aktuális teljesítményének és terheltségének függvényében osztaná ki a munkát, mondja Abadi. Harmadrészt pedig a párhuzamos kezelõk többségét nem tesztelték ki több ezer csomópontra, így váratlan jelenségek bukkanhatnak fel.
A javaslat
Erre kínál megoldást a a Hadoop, melyet Doug Cutting alkotott meg, és mára az Apache ernyõje alá tartozik, legnagyobb fejlesztõje és egyik felhasználója pedig a Yahoo!, de alkalmazza az Amazon, a Facebook, az ImageShack és a Last.fm is. A Hadoop egy Javában írt keretrendszer, melynek célja elosztott alkalmazások kiszolgálása. A projekt számos alkotóelembõl épül fel, köztük  a HDFS elosztott fájlrendszerrel, a HBase elosztott adatbáziskezelõvel, a Hive adattárház-infrastruktúrával, a Google által kidolgozott MapReduce elosztott feldolgozó keretrendszerrel, vagy a ZooKeeper menendzsment-szolgáltatással. A Hadoop dinamikus feladatütemezõvel, és magasabb fokú hibatûrõ képeségekkel bír, így jobban skálázható is.
A HadoopDB kezdeményezés célja, hogy a Hadoopnál jobb, a párhuzamos adatbázis-kezelõkéhez közelítõ teljesítményt kínáljon, miközben megtartja skálázódási képességét. A jobb analitikai teljesítmény érdekében a fejlesztõk a nyílt forrású PostgreSQL kezelõt választották az adatbázis- réteghez, a Hadoop HDFS-t az adatok tárolásához, a lekérdezéseket a csomópontok számára szétbontó, majd a válaszokat egyesítõ MapReduce keretrendszert feldolgozásához, míg egy módosított Hive felelt a lekérdezések bevitelére.

Az Amazon EC2 cloudjában, 10-100 géppel tesztelõ kutatók azt találták, hogy a PostgreSQL bevetésével a komplex feldolgozást igénylõ feladatok futása drasztikusan meggyorsult az eredeti Hadoop implementációhoz képest, egyes esetekben két-háromszoros, néhol pedig akár százszoros különbségeket mutatva a feladatok lefutási idejében. A HadoopDB teljesítménye messze elmarad ugyanakkor az olyan kereskedelmi párhuzamosított analitikai adatkezelõktól, mint amilyen a tanulmányban szereplõ Vertica vagy DBMS-X is.
Mindez azonban leginkább a kezdetleges, optimalizálatlan implementáció, továbbá a PostgreSQL  beállításainak (például be nem kapcsolt tömörítés) eredménye, melyek kezelésével további drasztikus gyorsulás várható, hogy egy igazán versenyképes, extrém skálázódású és magas teljesítményt kínáló ingyenes és nyílt forráskódú analitikai rendszer szülessen. A kutatók leszögezik, hogy reményeik szerint a jövõben több adatbázis-kezelõ is választható lesz a HadoopDB-hez, így például MySQL is. A teljesítmény további fokozása érdekében oszloporientált letárolást használó kezelõk bevetését is tervezik, melyek jobban illeszkednek az analitikai (OLAP) feladatokhoz.
A kísérlet ráadásul rámutatott arra is, hogy Hadoop-alapokon a hibákat és heterogén környezetet sokkal jobban türõ rendszer alakítható ki, mint a kisméretû fürtökön nyújtott teljesítményre koncentráló kereskedelmi szoftverekkel. A teljesítménybajnok Vertica például egy tízbõl egy csomópont lekérdezés közbeni leállásakor kevesebb mint felére lassult vissza, a végrehajtás 2,3-szoros idõt vett igénybe, miközben az egyik csomópont mesterséges lelassításakor (például túlterhelés szimulációja) ennél is nagyobb sokkot szenvedett el, a lekérdezés 2,75-szörös idõt vett igénybe -- ezzel szemben a HadoopDB mindössze rendre 13 és 26 százalékot veszített a teljesítményébõl.	     
                  
                  
                  
                   